"""Data models for video generation."""

from enum import Enum
from pathlib import Path
from typing import Optional

from pydantic import BaseModel, Field, field_validator

from socials_automator.constants import (
    VIDEO_WIDTH,
    VIDEO_HEIGHT,
    VIDEO_DEFAULT_DURATION_SECONDS,
    SUBTITLE_FONT_SIZE_DEFAULT,
    SUBTITLE_FONT_COLOR,
    SUBTITLE_HIGHLIGHT_COLOR,
    SUBTITLE_STROKE_COLOR,
    SUBTITLE_STROKE_WIDTH,
)


class SubtitleAnimation(str, Enum):
    """Subtitle animation styles."""

    POP = "pop"
    FADE = "fade"
    SLIDE = "slide"


class SubtitlePosition(str, Enum):
    """Subtitle position on screen."""

    TOP = "top"
    CENTER = "center"
    BOTTOM = "bottom"


class VideoScene(BaseModel):
    """Single scene in the video."""

    text: str = Field(..., description="Narration text for this scene")
    duration_seconds: float = Field(..., gt=0, description="Target duration in seconds")
    video_keywords: list[str] = Field(
        ..., min_length=1, description="Keywords to search Pexels"
    )

    @field_validator("video_keywords")
    @classmethod
    def validate_keywords(cls, v: list[str]) -> list[str]:
        """Ensure keywords are not empty strings."""
        return [kw.strip() for kw in v if kw.strip()]


class VideoScript(BaseModel):
    """Complete video script generated by AI."""

    title: str = Field(..., min_length=1, description="Video title")
    hook: str = Field(..., min_length=1, description="Opening hook (first 3 seconds)")
    scenes: list[VideoScene] = Field(
        ..., min_length=1, description="List of video scenes"
    )
    cta: str = Field(..., min_length=1, description="Call to action (last scene)")
    total_duration: int = Field(default=VIDEO_DEFAULT_DURATION_SECONDS, ge=15, le=180, description="Target duration")

    @property
    def full_narration(self) -> str:
        """Get complete narration text."""
        parts = [self.hook]
        parts.extend(scene.text for scene in self.scenes)
        parts.append(self.cta)
        return " ".join(parts)

    @property
    def word_count(self) -> int:
        """Get total word count for narration."""
        return len(self.full_narration.split())

    def estimated_duration(self, words_per_minute: int = 150) -> float:
        """Estimate speech duration based on word count."""
        return (self.word_count / words_per_minute) * 60


class WordTimestamp(BaseModel):
    """Single word with timing information."""

    word: str
    start_ms: int = Field(..., ge=0)
    end_ms: int = Field(..., ge=0)

    @property
    def start_seconds(self) -> float:
        """Get start time in seconds."""
        return self.start_ms / 1000.0

    @property
    def end_seconds(self) -> float:
        """Get end time in seconds."""
        return self.end_ms / 1000.0

    @property
    def duration_ms(self) -> int:
        """Get duration in milliseconds."""
        return self.end_ms - self.start_ms


class VoiceoverResult(BaseModel):
    """Result of TTS generation."""

    audio_path: Path
    srt_path: Path
    duration_seconds: float
    word_timestamps: list[WordTimestamp] = Field(default_factory=list)


class VideoClip(BaseModel):
    """Downloaded video clip information."""

    path: Path
    source_url: str
    duration_seconds: float
    width: int
    height: int
    scene_index: int
    keywords_used: list[str]

    @property
    def aspect_ratio(self) -> float:
        """Calculate aspect ratio."""
        return self.width / self.height

    @property
    def is_portrait(self) -> bool:
        """Check if video is portrait orientation."""
        return self.height > self.width

    @property
    def is_9_16(self) -> bool:
        """Check if video is close to 9:16 aspect ratio."""
        target = 9 / 16  # 0.5625
        return abs(self.aspect_ratio - target) < 0.1


class SubtitleStyle(BaseModel):
    """Subtitle styling configuration."""

    font: str = "Montserrat-Bold"
    font_size: int = Field(default=SUBTITLE_FONT_SIZE_DEFAULT, ge=20, le=120)
    color: str = SUBTITLE_FONT_COLOR
    highlight_color: str = SUBTITLE_HIGHLIGHT_COLOR
    stroke_color: str = SUBTITLE_STROKE_COLOR
    stroke_width: int = Field(default=SUBTITLE_STROKE_WIDTH, ge=0, le=10)
    position: SubtitlePosition = SubtitlePosition.CENTER
    animation: SubtitleAnimation = SubtitleAnimation.POP


class VideoOutput(BaseModel):
    """Final video output information."""

    script_path: Path
    audio_path: Path
    srt_path: Path
    clips_dir: Path
    assembled_path: Path
    final_path: Path
    thumbnail_path: Optional[Path] = None
    duration_seconds: float
    resolution: tuple[int, int] = (VIDEO_WIDTH, VIDEO_HEIGHT)


class GenerationProgress(BaseModel):
    """Track video generation progress."""

    stage: str
    progress: float = Field(..., ge=0, le=1)
    message: str
    current_scene: Optional[int] = None
    total_scenes: Optional[int] = None


class VideoGenerationError(Exception):
    """Base exception for video generation errors."""

    pass


class ScriptGenerationError(VideoGenerationError):
    """Error during script generation."""

    pass


class TTSError(VideoGenerationError):
    """Error during text-to-speech generation."""

    pass


class StockFootageError(VideoGenerationError):
    """Error during stock footage retrieval."""

    pass


class VideoAssemblyError(VideoGenerationError):
    """Error during video assembly."""

    pass


class SubtitleError(VideoGenerationError):
    """Error during subtitle rendering."""

    pass
