# Model Adapter Configurations
# Auto-detection patterns and settings for different LLM models
#
# When LMStudio loads a model, the adapter detects its type and applies
# appropriate settings (timeouts, response parsing, thinking mode, etc.)

# Model families with their detection patterns and configurations
adapters:
  # ==========================================================================
  # REASONING MODELS (generate thinking tokens before response)
  # ==========================================================================

  glm-4:
    description: "GLM-4.x series (reasoning models with vision)"
    patterns:
      - "glm-4"
      - "glm4"
      - "GLM-4"
      - "GLM4"
    capabilities:
      reasoning: true
      vision: true
      tool_use: true
    settings:
      timeout_multiplier: 2.5  # Reasoning takes longer
      temperature: 0.8         # Recommended by model.yaml
      top_k: 2
      top_p: 0.6
      repeat_penalty: 1.1
    extra_body:
      # Multiple params to try disabling thinking (different backends)
      enable_thinking: false
      thinking:
        type: "disabled"
      chat_template_kwargs:
        enable_thinking: false
    response:
      # Where to find actual content if primary field is empty
      primary_field: "content"
      fallback_field: "reasoning_content"
      # Extract JSON from reasoning if needed
      extract_json_from_reasoning: true

  qwen3:
    description: "Qwen3 series (reasoning models)"
    patterns:
      - "qwen3"
      - "qwen-3"
      - "Qwen3"
      - "Qwen-3"
    capabilities:
      reasoning: true
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 2.0
    extra_body:
      enable_thinking: false
      chat_template_kwargs:
        enable_thinking: false
    response:
      primary_field: "content"
      fallback_field: "reasoning_content"

  deepseek-r1:
    description: "DeepSeek R1 (reasoning model)"
    patterns:
      - "deepseek-r1"
      - "deepseek_r1"
      - "DeepSeek-R1"
    capabilities:
      reasoning: true
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 3.0  # Heavy reasoning
    extra_body:
      enable_thinking: false
    response:
      primary_field: "content"
      fallback_field: "reasoning_content"

  o1:
    description: "OpenAI o1 series (reasoning models)"
    patterns:
      - "o1-"
      - "o1_"
    capabilities:
      reasoning: true
      vision: false
      tool_use: false
    settings:
      timeout_multiplier: 3.0
    response:
      primary_field: "content"
      # o1 doesn't expose reasoning_content via API

  # ==========================================================================
  # INSTRUCTION-TUNED MODELS (direct responses, no reasoning phase)
  # ==========================================================================

  qwen2:
    description: "Qwen2.x series (fast instruction models)"
    patterns:
      - "qwen2"
      - "qwen-2"
      - "Qwen2"
    capabilities:
      reasoning: false
      vision: false  # Qwen2-VL has vision, detected separately
      tool_use: true
    settings:
      timeout_multiplier: 1.0
      temperature: 0.7

  llama:
    description: "Meta Llama series"
    patterns:
      - "llama"
      - "Llama"
      - "meta-llama"
    capabilities:
      reasoning: false
      vision: false  # Llama-3.2-Vision detected separately
      tool_use: true
    settings:
      timeout_multiplier: 1.0

  mistral:
    description: "Mistral AI models"
    patterns:
      - "mistral"
      - "Mistral"
      - "mixtral"
      - "Mixtral"
    capabilities:
      reasoning: false
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 1.0

  phi:
    description: "Microsoft Phi series"
    patterns:
      - "phi-"
      - "phi_"
      - "Phi-"
    capabilities:
      reasoning: false
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 1.0

  gemma:
    description: "Google Gemma series"
    patterns:
      - "gemma"
      - "Gemma"
    capabilities:
      reasoning: false
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 1.0

  codestral:
    description: "Mistral Codestral (code-focused)"
    patterns:
      - "codestral"
      - "Codestral"
    capabilities:
      reasoning: false
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 1.0
      temperature: 0.3  # Lower for code

  devstral:
    description: "Mistral Devstral (dev-focused)"
    patterns:
      - "devstral"
      - "Devstral"
    capabilities:
      reasoning: false
      vision: false
      tool_use: true
    settings:
      timeout_multiplier: 1.0

  # ==========================================================================
  # VISION MODELS (can process images)
  # ==========================================================================

  llava:
    description: "LLaVA vision-language models"
    patterns:
      - "llava"
      - "LLaVA"
    capabilities:
      reasoning: false
      vision: true
      tool_use: false
    settings:
      timeout_multiplier: 1.5  # Vision processing adds time

  # ==========================================================================
  # DEFAULT FALLBACK
  # ==========================================================================

  default:
    description: "Default configuration for unknown models"
    patterns: []  # Matches nothing, used as fallback
    capabilities:
      reasoning: false
      vision: false
      tool_use: false
    settings:
      timeout_multiplier: 1.0
      temperature: 0.7
    response:
      primary_field: "content"
      fallback_field: null

# Global settings
global:
  # Base timeout in seconds (multiplied by adapter's timeout_multiplier)
  base_timeout: 120

  # Cache model detection for this many seconds
  detection_cache_ttl: 300

  # Log level for adapter operations
  log_level: "INFO"
